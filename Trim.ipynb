{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def detect_nonsilence_regions(filename, silence_threshold=0.05, min_duration=0.15, target_duration=0.3, sr=None):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(filename, sr=sr)\n",
    "\n",
    "    # Detect non-silent regions\n",
    "    non_silent_samples = librosa.effects.split(y, top_db=silence_threshold)\n",
    "\n",
    "    # Filter out regions shorter than min_duration\n",
    "    min_samples = int(min_duration * sr)\n",
    "    non_silent_samples = [interval for interval in non_silent_samples if interval[1] - interval[0] >= min_samples]\n",
    "\n",
    "    # Adjust start and end points to make duration equal to target_duration\n",
    "    target_samples = int(target_duration * sr)\n",
    "    adjusted_samples = []\n",
    "    for start, end in non_silent_samples:\n",
    "        diff = target_samples - (end - start)\n",
    "        start -= diff // 2\n",
    "        end += diff // 2\n",
    "\n",
    "        # Handle cases where start or end goes out of bounds\n",
    "        start = max(0, start)\n",
    "        end = min(len(y), end)\n",
    "\n",
    "        adjusted_samples.append((start, end))\n",
    "\n",
    "    return adjusted_samples\n",
    "\n",
    "def extract_and_save_regions(filename, output_prefix, regions, sr=None):\n",
    "    y, _ = librosa.load(filename, sr=sr)\n",
    "    for i, (start, end) in enumerate(regions):\n",
    "        sf.write(f\"{output_prefix}_region_{i}.wav\", y[start:end], sr)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"HackRF_20230920_152800Z_433000kHz_IQ.wav\"\n",
    "    regions = detect_nonsilence_regions(filename)\n",
    "    extract_and_save_regions(filename, \"output\", regions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import os\n",
    "\n",
    "def trim_audio_to_duration(file_path, output_path, desired_duration=300, min_silence_len=100, silence_thresh=-50):\n",
    "    \"\"\"\n",
    "    Trims silence from the start and end of an audio file and ensures the resulting file does not exceed the desired duration.\n",
    "    Prioritizes retaining the latter part of the audio signal if the non-silent duration exceeds the desired length.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: Path to the WAV file to process.\n",
    "    - output_path: Path where the trimmed audio will be saved.\n",
    "    - desired_duration: Maximum duration of the resulting audio file after trimming (in ms).\n",
    "    - min_silence_len: Minimum length of silence to be used for detection (in ms).\n",
    "    - silence_thresh: Silence threshold (in dBFS).\n",
    "    \"\"\"\n",
    "    audio = AudioSegment.from_wav(file_path)\n",
    "    \n",
    "    # Detect nonsilent parts\n",
    "    nonsilent_ranges = detect_nonsilent(audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh)\n",
    "    \n",
    "    # If no nonsilent ranges are detected, the audio is probably all silence.\n",
    "    if not nonsilent_ranges:\n",
    "        raise ValueError(\"No non-silent segments detected in the audio.\")\n",
    "    \n",
    "    # Only consider the start of the first non-silent segment and the end of the last non-silent segment.\n",
    "    start, _ = nonsilent_ranges[0]\n",
    "    _, end = nonsilent_ranges[-1]\n",
    "    signal = audio[start:end]\n",
    "\n",
    "    # If signal length exceeds the desired_duration, truncate from the start to prioritize the latter part\n",
    "    if len(signal) > desired_duration:\n",
    "        signal = signal[-desired_duration:]\n",
    "    \n",
    "    # Save the trimmed audio\n",
    "    signal.export(output_path, format=\"wav\")\n",
    "\n",
    "def process_folder(source_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Processes all WAV files in the source folder and saves the trimmed files in the output folder.\n",
    "    \n",
    "    Parameters:\n",
    "    - source_folder: Path to the folder containing WAV files.\n",
    "    - output_folder: Path to the folder where trimmed files will be saved.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for file_name in os.listdir(source_folder):\n",
    "        if file_name.endswith('.wav'):\n",
    "            source_file_path = os.path.join(source_folder, file_name)\n",
    "            trimmed_file_name = \"trimmed_\" + file_name\n",
    "            output_file_path = os.path.join(output_folder, trimmed_file_name)\n",
    "            trim_audio_to_duration(source_file_path, output_file_path)\n",
    "\n",
    "# Usage\n",
    "input_directory = r\"C:\\Users\\CAN-LAB\\Desktop\\test\"\n",
    "output_directory = r\"C:\\Users\\CAN-LAB\\Desktop\\test(Trimmed)\"\n",
    "process_folder(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import os\n",
    "\n",
    "def trim_audio(file_path, output_path, min_silence_len=500, silence_thresh=-20, desired_duration=300):\n",
    "    \"\"\"\n",
    "    Trims silence from an audio file and ensures the resulting file has a fixed desired duration.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: Path to the WAV file to process.\n",
    "    - output_path: Path where the trimmed audio will be saved.\n",
    "    - min_silence_len: Minimum length of silence to be used for detection (in ms).\n",
    "    - silence_thresh: Silence threshold (in dBFS).\n",
    "    - desired_duration: Desired duration of the resulting audio file after trimming (in ms).\n",
    "    \"\"\"\n",
    "    audio = AudioSegment.from_wav(file_path)\n",
    "    \n",
    "    # Detect nonsilent parts\n",
    "    nonsilent_ranges = detect_nonsilent(audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh)\n",
    "    \n",
    "    # Concatenate nonsilent parts to get the signal\n",
    "    signal = AudioSegment.empty()\n",
    "    for start, end in nonsilent_ranges:\n",
    "        signal += audio[start:end]\n",
    "    \n",
    "    # Calculate the padding needed to center the signal in the desired duration\n",
    "    total_padding = desired_duration - len(signal)\n",
    "    start_padding = total_padding // 2\n",
    "    end_padding = total_padding - start_padding\n",
    "\n",
    "    start_silence = AudioSegment.silent(duration=start_padding)\n",
    "    end_silence = AudioSegment.silent(duration=end_padding)\n",
    "    \n",
    "    # Concatenate silent segments with the signal\n",
    "    trimmed_signal = start_silence + signal + end_silence\n",
    "    \n",
    "    # Save the trimmed audio\n",
    "    trimmed_signal.export(output_path, format=\"wav\")\n",
    "\n",
    "def process_folder(source_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Processes all WAV files in the source folder and saves the trimmed files in the output folder.\n",
    "    \n",
    "    Parameters:\n",
    "    - source_folder: Path to the folder containing WAV files.\n",
    "    - output_folder: Path to the folder where trimmed files will be saved.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for file_name in os.listdir(source_folder):\n",
    "        if file_name.endswith('.wav'):\n",
    "            source_file_path = os.path.join(source_folder, file_name)\n",
    "            trimmed_file_name = file_name.replace('.wav', ' (trimmed).wav')\n",
    "            output_file_path = os.path.join(output_folder, trimmed_file_name)\n",
    "            trim_audio(source_file_path, output_file_path)\n",
    "\n",
    "# Usage\n",
    "source_folder = r\"C:\\Users\\CAN-LAB\\Desktop\\test\"\n",
    "output_folder = r\"C:\\Users\\CAN-LAB\\Desktop\\test(Trimmed)\"\n",
    "process_folder(source_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
