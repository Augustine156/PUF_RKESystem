{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import pypuf.io\n",
    "import pypuf.simulation\n",
    "import time\n",
    "import hashlib\n",
    "import busio\n",
    "import board\n",
    "import digitalio\n",
    "import pickle\n",
    "import adafruit_rfm9x\n",
    "import zlib\n",
    "import time\n",
    "from digitalio import DigitalInOut, Direction, Pull\n",
    "import adafruit_ssd1306\n",
    "import subprocess\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "from tflite_runtime import interpreter\n",
    "import librosa\n",
    "\n",
    "# Initialize the OLED display\n",
    "i2c = board.I2C()\n",
    "oled = adafruit_ssd1306.SSD1306_I2C(128, 32, i2c)\n",
    "\n",
    "# Function to update the OLED display with status\n",
    "def update_display(status):\n",
    "    oled.fill(0)  # Clear the display\n",
    "    oled.text(\"Car Status:\",10, 5, 1)\n",
    "    oled.text(status,10, 15, 1)\n",
    "    oled.show()  # Update the OLED display\n",
    "\n",
    "\n",
    "RADIO_FREQ_MHZ = 433.0\n",
    "CS = digitalio.DigitalInOut(board.CE1)\n",
    "RESET = digitalio.DigitalInOut(board.D25)\n",
    "\n",
    "spi = busio.SPI(board.SCK, MOSI=board.MOSI, MISO=board.MISO)\n",
    "rfm9x = adafruit_rfm9x.RFM9x(spi, CS, RESET, RADIO_FREQ_MHZ)\n",
    "\n",
    "rfm9x.tx_power = 23\n",
    "# enable CRC checking\n",
    "rfm9x.enable_crc = True\n",
    "# set delay before transmitting ACK (seconds)\n",
    "rfm9x.ack_delay = 0.1\n",
    "# set node addresses\n",
    "rfm9x.node = 1\n",
    "rfm9x.destination = 2\n",
    "rfm9x.ack_retries = 5\n",
    "rfm9x.ack_wait = 2.0  # 2 seconds\n",
    "\n",
    "puf_BITS = 32\n",
    "puf_SEED = 1\n",
    "puf_SETS = 8\n",
    "\n",
    "# Load your TFLite model\n",
    "model = interpreter.Interpreter(model_path=\"/home/hello/Desktop/PUF_RKESystem-main/RF/CNN-90per.tflite\")\n",
    "model.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = model.get_input_details()\n",
    "output_details = model.get_output_details()\n",
    "\n",
    "# Get the input and output tensor shapes and data types\n",
    "input_shape = input_details[0]['shape']\n",
    "output_shape = output_details[0]['shape']\n",
    "input_dtype = input_details[0]['dtype']\n",
    "output_dtype = output_details[0]['dtype']\n",
    "\n",
    "# Load and preprocess the WAV file\n",
    "def preprocess_wav(file_path, input_shape):\n",
    "    # Load the audio file using librosa\n",
    "    audio, sample_rate = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    # Ensure the audio length matches the expected input shape\n",
    "    if len(audio) != input_shape[1]:\n",
    "        if len(audio) < input_shape[1]:\n",
    "            # If the audio is shorter than expected, pad it with zeros on both sides to match the input shape\n",
    "            padding = input_shape[1] - len(audio)\n",
    "            audio = np.pad(audio, (0, padding), 'constant')\n",
    "        else:\n",
    "            # If the audio is longer than expected, trim it down to match the input shape\n",
    "            audio = audio[:input_shape[1]]\n",
    "    return audio\n",
    "\n",
    "def trim_and_pad_audio(file_path, output_path, desired_duration=300, min_silence_len=100, silence_thresh=-30):\n",
    "    \"\"\"\n",
    "    Trims silence from the start and end of an audio file and ensures the resulting file is exactly the desired duration (in ms).\n",
    "    If the audio is shorter than the desired duration, it is padded with silence evenly at both the beginning and end.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: Path to the WAV file to process.\n",
    "    - output_path: Path where the trimmed and padded audio will be saved.\n",
    "    - desired_duration: Desired duration of the resulting audio file after trimming and padding (in ms).\n",
    "    - min_silence_len: Minimum length of silence to be used for detection (in ms).\n",
    "    - silence_thresh: Silence threshold (in dBFS).\n",
    "    \"\"\"\n",
    "    audio = AudioSegment.from_wav(file_path)\n",
    "    \n",
    "    # Detect nonsilent parts\n",
    "    nonsilent_ranges = detect_nonsilent(audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh)\n",
    "    \n",
    "    # If no nonsilent ranges are detected, the audio is probably all silence.\n",
    "    if not nonsilent_ranges:\n",
    "        raise ValueError(\"No non-silent segments detected in the audio.\")\n",
    "    \n",
    "    # Only consider the start of the first non-silent segment and the end of the last non-silent segment.\n",
    "    start, _ = nonsilent_ranges[0]\n",
    "    _, end = nonsilent_ranges[-1]\n",
    "    signal = audio[start:end]\n",
    "\n",
    "    # Calculate the actual duration of the trimmed audio\n",
    "    actual_duration = len(signal)\n",
    "    if actual_duration > desired_duration:\n",
    "        # Trim the audio to the desired duration\n",
    "        start_trim = (actual_duration - desired_duration) // 2\n",
    "        end_trim = (actual_duration - desired_duration) - start_trim\n",
    "        signal = signal[start_trim:-end_trim]\n",
    "    elif actual_duration < desired_duration:  \n",
    "        # Calculate the required padding on both sides\n",
    "        padding_duration = desired_duration - actual_duration\n",
    "        left_padding_duration = padding_duration // 2\n",
    "        right_padding_duration = padding_duration - left_padding_duration\n",
    "        \n",
    "        # Create silence for padding\n",
    "        left_padding_silence = AudioSegment.silent(duration=left_padding_duration)\n",
    "        right_padding_silence = AudioSegment.silent(duration=right_padding_duration)\n",
    "        \n",
    "        # Add padding to both the beginning and end\n",
    "        signal = left_padding_silence + signal + right_padding_silence\n",
    "    else:\n",
    "        # The audio is already the desired duration\n",
    "        pass\n",
    "    # Save the trimmed and padded audio\n",
    "    signal.export(output_path, format=\"wav\")\n",
    "\n",
    "\n",
    "def send_message(key, value):\n",
    "    print(f\"Sending {key} from Car to Key...\")\n",
    "    if not isinstance(value, bytes):\n",
    "        value = bytes(value, 'utf-8')\n",
    "    \n",
    "    MAX_CHUNK_SIZE = 170  # Adjusted chunk size\n",
    "    num_chunks = (len(value) + MAX_CHUNK_SIZE - 1) // MAX_CHUNK_SIZE\n",
    "    for i in range(num_chunks):\n",
    "        chunk = value[i * MAX_CHUNK_SIZE: (i + 1) * MAX_CHUNK_SIZE]\n",
    "        rfm9x.send_with_ack(chunk)  # Send data as bytes\n",
    "        if i < num_chunks - 1:  # If there are more chunks to send, add a delay\n",
    "            time.sleep(0.1)  # Adjust this delay as needed\n",
    "    print(f\"{key} has been sent\")\n",
    "\n",
    "\n",
    "# Replace receive_message with LoRa reception\n",
    "def receive_message(key):\n",
    "    print(f\"Receiving {key} from Key to Car...\")\n",
    "    while True:\n",
    "        data = rfm9x.receive(with_ack=True)\n",
    "        if data is not None:\n",
    "            print(f\"Received {key}\")\n",
    "            return data\n",
    "        time.sleep(1)  # Add a small delay before checking again\n",
    "\n",
    "def hackrf_capture_start():\n",
    "    \"\"\"\n",
    "    Starts capturing signals using HackRF.\n",
    "    Returns the started process.\n",
    "    \"\"\"\n",
    "    hackrf_process = subprocess.Popen([\n",
    "        \"hackrf_transfer\",\n",
    "        \"-w\",  # Save as WAV file\n",
    "        \"-f\", \"433000000\",  # Frequency: 433 MHz\n",
    "        \"-s\", \"2000000\",    # Sample rate: 2.0 MSPS\n",
    "        \"-l\", \"16\",         # IF gain: 16\n",
    "        \"-g\", \"14\"          # Baseband gain: 14\n",
    "    ])\n",
    "    return hackrf_process\n",
    "\n",
    "def hackrf_capture_stop(hackrf_process):\n",
    "    \"\"\"\n",
    "    Stops the HackRF capture process.\n",
    "    \"\"\"\n",
    "    hackrf_process.terminate()\n",
    "    hackrf_process.wait()\n",
    "    print(\"HackRF capture complete.\")\n",
    "    \n",
    "def remove_files_in_folder(folder):\n",
    "    \"\"\"Remove all WAV files in the specified folder.\"\"\"\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            os.remove(file_path)\n",
    "\n",
    "def move_and_trim_files(src_folder, dest_folder):\n",
    "    # Ensure the destination folder exists\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "    \n",
    "    # Remove all WAV files in the destination folder\n",
    "    remove_files_in_folder(dest_folder)\n",
    "\n",
    "    # Iterate through all files in the source directory\n",
    "    for filename in os.listdir(src_folder):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            src_path = os.path.join(src_folder, filename)\n",
    "            dest_path = os.path.join(dest_folder, filename)\n",
    "            \n",
    "            # Load the audio file to check its duration\n",
    "            audio = AudioSegment.from_wav(src_path)\n",
    "            \n",
    "            # Check if the audio duration is longer than 5 seconds\n",
    "            if len(audio) > 5000:  # Duration is in milliseconds\n",
    "                # Trim the audio to the last 5 seconds\n",
    "                start_time = len(audio) - 5000  # Start time for the last 5 seconds\n",
    "                trimmed_audio = audio[start_time:]\n",
    "                \n",
    "                # Export the trimmed audio\n",
    "                trimmed_audio.export(dest_path, format=\"wav\")\n",
    "                \n",
    "                # Now proceed to trim_and_pad_audio for further processing\n",
    "                trim_and_pad_audio(dest_path, dest_path)\n",
    "            else:\n",
    "                # Audio is shorter than 5 seconds, use trim_and_pad_audio directly\n",
    "                trim_and_pad_audio(src_path, dest_path)\n",
    "            \n",
    "            # Remove the original file from the source folder\n",
    "            os.remove(src_path)\n",
    "            \n",
    "            \n",
    "while True:\n",
    "    with open('car_data.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    remove_files_in_folder(os.getcwd())\n",
    "    hackrf_process = hackrf_capture_start()\n",
    "\n",
    "    key_id = data['Key_id']\n",
    "    challenge_ndarray = data['Challenge']\n",
    "\n",
    "    response_str = data['Response']\n",
    "    Ks = data['Ks']\n",
    "\n",
    "    # Process Ks to get Ks_ndarray\n",
    "    Ks_ndarray = np.array([int(c) for c in Ks], dtype=np.int8)\n",
    "\n",
    "    \"\"\"\n",
    "    Receive MA1\n",
    "    \"\"\"\n",
    "\n",
    "    received_data = receive_message('MA1_data').decode('utf-8')\n",
    "    start_time = time.time()\n",
    "    message_data = json.loads(received_data)\n",
    "\n",
    "    # Stop the HackRF capture\n",
    "    hackrf_capture_stop(hackrf_process)\n",
    "    current_folder = os.getcwd()  # Gets the current directory\n",
    "    destination_folder = \"signal\"  # Replace with your desired path\n",
    "    move_and_trim_files(current_folder, destination_folder)\n",
    "    signal_folder = \"signal/\"  # Specify the folder where the WAV file is located\n",
    "\n",
    "    # List all files in the signal folder\n",
    "    signal_files = os.listdir(signal_folder)\n",
    "\n",
    "    # Filter for WAV files\n",
    "    wav_files = [f for f in signal_files if f.endswith(\".wav\")]\n",
    "\n",
    "    if len(wav_files) == 1:\n",
    "        # Only proceed if there is exactly one WAV file in the folder\n",
    "        wav_file_path = os.path.join(signal_folder, wav_files[0])\n",
    "\n",
    "        # Preprocess the WAV file\n",
    "        input_data = preprocess_wav(wav_file_path, input_shape)\n",
    "        # Reshape the audio data to match the expected input shape\n",
    "        input_data =  np.expand_dims(np.expand_dims(input_data, axis=0), axis=-1)\n",
    "        # Set the input tensor\n",
    "        model.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "        # Run inference\n",
    "        model.invoke()\n",
    "\n",
    "        # Get the output tensor\n",
    "        output_data = model.get_tensor(output_details[0]['index'])\n",
    "\n",
    "        # # Assuming a threshold of 0.5 for binary classification\n",
    "        threshold = 0.60\n",
    "        binary_prediction = (output_data > threshold).astype(np.int32)\n",
    "\n",
    "        # # Output confidence (probability)\n",
    "        confidence = output_data[0][0]\n",
    "\n",
    "        # # Use binary_prediction as your model's prediction and confidence as the probability\n",
    "        print(\"Predicted class:\", binary_prediction)\n",
    "        print(\"Confidence:\", confidence)\n",
    "        # print(output_data)\n",
    "        # predict_result=output_data.argmax()\n",
    "       \n",
    "        # Continue with the rest of code 2 depending on binary_prediction\n",
    "        if binary_prediction == 1:\n",
    "            # Code to execute when binary_prediction is 1\n",
    "            print(\"Proceed with code 2\")\n",
    "            # Insert the remaining part of code 2 here\n",
    "        else:\n",
    "            remove_files_in_folder(os.getcwd())\n",
    "            # Code to execute when binary_prediction is not 1\n",
    "            print(\"Predicted class is not 1. Returning to start of while loop.\")\n",
    "            continue  # Return to the start of the while loop to wait for \"MA1_data\"\n",
    "    else:\n",
    "        print(\"There are no/above 1 WAV files in the 'signal' folder or there are multiple WAV files.\")\n",
    "        continue\n",
    "    key_id = message_data['ID']\n",
    "    Ni_encrypted = bytes.fromhex(message_data['Encrypted_Ni'])  # Convert hex string back to bytes\n",
    "\n",
    "    \"\"\"\n",
    "    Decode Ni\n",
    "    \"\"\"\n",
    "    Ni_encrypted = np.frombuffer(Ni_encrypted, dtype=np.int8).reshape(puf_BITS) # byte-> numpy array\n",
    "\n",
    "    Ni = Ni_encrypted ^ Ks_ndarray # decode(XOR)\n",
    "\n",
    "    Ni = np.array2string(Ni, separator='', prefix='', suffix='')[1:-1] # remove brackets and whitespace, type: numpy array-> string\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Generate & XOR Nc\n",
    "    \"\"\"\n",
    "    Nc = bin(random.getrandbits(puf_BITS))[2:].zfill(puf_BITS) #type: string\n",
    "\n",
    "    Nc_ndarray = np.array([int(c) for c in Nc], dtype= np.int8) #type: string -> numpy array\n",
    "\n",
    "    Nc_encrypted = Nc_ndarray ^ Ks_ndarray #type: numpy array\n",
    "    Nc_encryptedz_compressed = zlib.compress(Nc_encrypted.tobytes())\n",
    "    \"\"\"\n",
    "    XOR challenge\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    challenge_encrypted = challenge_ndarray ^ Ks_ndarray #type: numpy array\n",
    "\n",
    "    \"\"\"\n",
    "    Generate hash\n",
    "    \"\"\"\n",
    "    A0 = key_id + Ni + Ks + Nc\n",
    "\n",
    "    A0_hash_object = hashlib.sha256(A0.encode('utf-8'))\n",
    "\n",
    "    A0_hex_dig = A0_hash_object.hexdigest()\n",
    "    \"\"\"\n",
    "    Generate & XOR challenge new\n",
    "    \"\"\"\n",
    "    challenge_new = pypuf.io.random_inputs(puf_BITS, puf_SETS, puf_SEED) # Generate Challenge, type: numpy array\n",
    "\n",
    "    challenge_new_encrypted = challenge_new ^ Ks_ndarray #type: numpy array\n",
    "    challenge_encrypted_compressed = zlib.compress(challenge_encrypted.tobytes())\n",
    "    challenge_new_encrypted_compressed = zlib.compress(challenge_new_encrypted.tobytes())\n",
    "\n",
    "    \"\"\"\n",
    "    send MA2\n",
    "    \"\"\"\n",
    "    # Group the data into a dictionary\n",
    "    message_data = {\n",
    "        \"A0\": A0_hex_dig,\n",
    "        \"Encrypted_Nc\": Nc_encryptedz_compressed.hex(),\n",
    "        \"Encrypted_Challenge\": challenge_encrypted_compressed.hex(),\n",
    "        \"Encrypted_Challenge_New\": challenge_new_encrypted_compressed.hex()\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a JSON string and send\n",
    "    message_json = json.dumps(message_data).encode('utf-8')\n",
    "\n",
    "    send_message(\"Combined_Data\", zlib.compress(message_json))\n",
    "\n",
    "    \"\"\"\n",
    "    receive MA3\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    compressed_data = receive_message(\"Compressed_MA3_Data\")\n",
    "    decompressed_data = zlib.decompress(compressed_data)\n",
    "\n",
    "    # Parse the combined data from JSON\n",
    "    combined_data = json.loads(decompressed_data.decode('utf-8'))\n",
    "\n",
    "    # Extract individual components\n",
    "    A1_hex_dig = combined_data[\"A1\"]\n",
    "    response_encrypted = bytes.fromhex(combined_data[\"Encrypted_Response\"])\n",
    "    response_new_encrypted = bytes.fromhex(combined_data[\"Encrypted_Response_New\"])\n",
    "    cmd = combined_data[\"Command\"]\n",
    "    expiration_time = combined_data[\"ExpirationTime\"]\n",
    "    \n",
    "    now_time = int(time.time())\n",
    "    \n",
    "    # Update the car status based on the command\n",
    "    if cmd == \"lock\":\n",
    "        car_status = \"Locked\"\n",
    "        # Update the OLED display with the status\n",
    "        update_display(car_status)\n",
    "    elif cmd == \"unlock\":\n",
    "        car_status = \"Unlocked\"\n",
    "        # Update the OLED display with the status\n",
    "        update_display(car_status)\n",
    "    else:\n",
    "        # Handle other commands as needed\n",
    "        car_status = \"Unknown\"  # Set a default status\n",
    "\n",
    "    \n",
    "    if expiration_time >= now_time:\n",
    "\n",
    "        \"\"\"\n",
    "        Decode Response & Response new\n",
    "        \"\"\"\n",
    "\n",
    "        response_encrypted = np.frombuffer(response_encrypted, dtype=np.int8) # byte-> numpy array\n",
    "\n",
    "        response = response_encrypted ^ Ks_ndarray[0:8] # decode(XOR)\n",
    "\n",
    "        response_new_encrypted = np.frombuffer(response_new_encrypted, dtype=np.int8) # byte-> numpy array\n",
    "\n",
    "        response_new = response_new_encrypted ^ Ks_ndarray[0:8] # decode(XOR)\n",
    "\n",
    "        \"\"\"\n",
    "        Verify Response and A1\n",
    "        \"\"\"\n",
    "\n",
    "        puf = pypuf.simulation.XORArbiterPUF(puf_BITS, puf_SEED)\n",
    "\n",
    "        response_verified = puf.eval(challenge_ndarray) # produce response, type: numpy array\n",
    "        #Above should compare with response\n",
    "\n",
    "\n",
    "        response_str = np.array2string(response, separator='', prefix='', suffix='')[1:-1] #type: numpy array-> string\n",
    "\n",
    "        response_new_str = np.array2string(response_new, separator='', prefix='', suffix='')[1:-1] #type: numpy array-> string\n",
    "\n",
    "        A1_verified = key_id + Nc + Ks + response_str + response_new_str\n",
    "\n",
    "        A1_verified_hash_object = hashlib.sha256(A1_verified.encode('utf-8'))\n",
    "\n",
    "        A1_verified_hex_dig = A1_verified_hash_object.hexdigest()\n",
    "        if(A1_verified_hex_dig == A1_hex_dig):\n",
    "            if(np.array_equal(response, response_verified)):\n",
    "                # Print or use the car_status variable as needed in your code.\n",
    "                print(\"Car Status:\", car_status)\n",
    "                data = {\n",
    "                        'Key_id': key_id,\n",
    "                        'Challenge': challenge_new,\n",
    "                        'Response': response_new,\n",
    "                        'Ks': Ks\n",
    "                }\n",
    "                # print(data)\n",
    "                # Serialize the register_output dictionary and write to car_data.pkl\n",
    "                with open('car_data.pkl', 'wb') as f:\n",
    "                    pickle.dump(data, f)\n",
    "                        \n",
    "            else:\n",
    "                print(\"Failed Response verified\")\n",
    "        else:\n",
    "            print(\"Failed A1 verified\")\n",
    "        \n",
    "        \n",
    "        print(time.time()- start_time )\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        print(\"time was outdated\")\n",
    "    \n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
